{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Maslow's_Hierarchy_of_Needs.svg.png\" height = 600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import urllib.parse # combine URL components into URL string\n",
    "import wikipediaapi # query wikipedia through api\n",
    "\n",
    "from statsmodels.tsa.seasonal import STL # seasonal decompositions\n",
    "import statsmodels.tsa.stattools as smt\n",
    "\n",
    "\n",
    "import pickle #  to serialize and deserialize objects in Python\n",
    "import requests\n",
    "from scipy import signal\n",
    "import warnings\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pytrends\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wikipediaapi\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n",
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(19, 292)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/s4kdxzb13gz3xbwg60k83tmm0000gn/T/ipykernel_35453/2397408024.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pageview[row['Topics']] = get_pageviews_wiki(url)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>NASA_Exceptional_Engineering_Achievement_Medal</th>\n",
       "      <th>Laureus_Lifetime_Achievement_Award</th>\n",
       "      <th>Filmic_Achievement</th>\n",
       "      <th>TCA_Award_for_Outstanding_Achievement_in_Sports</th>\n",
       "      <th>Latin_Grammy_Lifetime_Achievement_Award</th>\n",
       "      <th>Confidence_Bay</th>\n",
       "      <th>Wechsler_Individual_Achievement_Test</th>\n",
       "      <th>Laurel_Award_for_TV_Writing_Achievement</th>\n",
       "      <th>Computerized_Achievement_Levels_Test</th>\n",
       "      <th>...</th>\n",
       "      <th>Confidence_Man_(band)</th>\n",
       "      <th>Lasker-Koshland_Special_Achievement_Award_in_Medical_Science</th>\n",
       "      <th>Confidence_Man_(Lost)</th>\n",
       "      <th>Confidence,_West_Virginia</th>\n",
       "      <th>TrueAchievements</th>\n",
       "      <th>Laurence_Olivier_Award_for_Outstanding_Achievement_in_an_Affiliate_Theatre</th>\n",
       "      <th>Major_achievements_in_roller_hockey_by_nation</th>\n",
       "      <th>Differential_Education_Achievement</th>\n",
       "      <th>Juno_International_Achievement_Award</th>\n",
       "      <th>Iran_Nuclear_Achievements_Protection_Act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>336</td>\n",
       "      <td>757</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>376</td>\n",
       "      <td>61</td>\n",
       "      <td>2072</td>\n",
       "      <td>264</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>4139</td>\n",
       "      <td>131</td>\n",
       "      <td>1018</td>\n",
       "      <td>69</td>\n",
       "      <td>355</td>\n",
       "      <td>284</td>\n",
       "      <td>84</td>\n",
       "      <td>255</td>\n",
       "      <td>61</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>318</td>\n",
       "      <td>2050</td>\n",
       "      <td>130</td>\n",
       "      <td>102</td>\n",
       "      <td>550</td>\n",
       "      <td>52</td>\n",
       "      <td>2264</td>\n",
       "      <td>250</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>2533</td>\n",
       "      <td>135</td>\n",
       "      <td>1151</td>\n",
       "      <td>69</td>\n",
       "      <td>377</td>\n",
       "      <td>193</td>\n",
       "      <td>95</td>\n",
       "      <td>317</td>\n",
       "      <td>54</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>234</td>\n",
       "      <td>724</td>\n",
       "      <td>104</td>\n",
       "      <td>108</td>\n",
       "      <td>436</td>\n",
       "      <td>77</td>\n",
       "      <td>2764</td>\n",
       "      <td>206</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>3371</td>\n",
       "      <td>128</td>\n",
       "      <td>1289</td>\n",
       "      <td>84</td>\n",
       "      <td>350</td>\n",
       "      <td>447</td>\n",
       "      <td>89</td>\n",
       "      <td>434</td>\n",
       "      <td>77</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>259</td>\n",
       "      <td>778</td>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>365</td>\n",
       "      <td>67</td>\n",
       "      <td>3386</td>\n",
       "      <td>228</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>2708</td>\n",
       "      <td>94</td>\n",
       "      <td>1119</td>\n",
       "      <td>101</td>\n",
       "      <td>409</td>\n",
       "      <td>530</td>\n",
       "      <td>102</td>\n",
       "      <td>370</td>\n",
       "      <td>68</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>218</td>\n",
       "      <td>780</td>\n",
       "      <td>90</td>\n",
       "      <td>76</td>\n",
       "      <td>391</td>\n",
       "      <td>63</td>\n",
       "      <td>2824</td>\n",
       "      <td>222</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>4209</td>\n",
       "      <td>107</td>\n",
       "      <td>1388</td>\n",
       "      <td>57</td>\n",
       "      <td>302</td>\n",
       "      <td>306</td>\n",
       "      <td>92</td>\n",
       "      <td>332</td>\n",
       "      <td>56</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>271</td>\n",
       "      <td>500</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "      <td>372</td>\n",
       "      <td>45</td>\n",
       "      <td>2048</td>\n",
       "      <td>129</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>3628</td>\n",
       "      <td>130</td>\n",
       "      <td>1219</td>\n",
       "      <td>72</td>\n",
       "      <td>413</td>\n",
       "      <td>432</td>\n",
       "      <td>89</td>\n",
       "      <td>261</td>\n",
       "      <td>49</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>406</td>\n",
       "      <td>520</td>\n",
       "      <td>114</td>\n",
       "      <td>89</td>\n",
       "      <td>411</td>\n",
       "      <td>64</td>\n",
       "      <td>1755</td>\n",
       "      <td>156</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>2038</td>\n",
       "      <td>112</td>\n",
       "      <td>1097</td>\n",
       "      <td>60</td>\n",
       "      <td>429</td>\n",
       "      <td>305</td>\n",
       "      <td>143</td>\n",
       "      <td>299</td>\n",
       "      <td>75</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>361</td>\n",
       "      <td>595</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "      <td>577</td>\n",
       "      <td>64</td>\n",
       "      <td>1778</td>\n",
       "      <td>192</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>1637</td>\n",
       "      <td>118</td>\n",
       "      <td>1008</td>\n",
       "      <td>48</td>\n",
       "      <td>400</td>\n",
       "      <td>321</td>\n",
       "      <td>88</td>\n",
       "      <td>251</td>\n",
       "      <td>70</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>278</td>\n",
       "      <td>603</td>\n",
       "      <td>91</td>\n",
       "      <td>86</td>\n",
       "      <td>665</td>\n",
       "      <td>53</td>\n",
       "      <td>2222</td>\n",
       "      <td>190</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>1535</td>\n",
       "      <td>132</td>\n",
       "      <td>1114</td>\n",
       "      <td>94</td>\n",
       "      <td>400</td>\n",
       "      <td>521</td>\n",
       "      <td>73</td>\n",
       "      <td>184</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>280</td>\n",
       "      <td>747</td>\n",
       "      <td>139</td>\n",
       "      <td>113</td>\n",
       "      <td>550</td>\n",
       "      <td>61</td>\n",
       "      <td>3143</td>\n",
       "      <td>189</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>1529</td>\n",
       "      <td>167</td>\n",
       "      <td>1201</td>\n",
       "      <td>109</td>\n",
       "      <td>408</td>\n",
       "      <td>402</td>\n",
       "      <td>108</td>\n",
       "      <td>220</td>\n",
       "      <td>65</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>404</td>\n",
       "      <td>650</td>\n",
       "      <td>138</td>\n",
       "      <td>113</td>\n",
       "      <td>753</td>\n",
       "      <td>68</td>\n",
       "      <td>2961</td>\n",
       "      <td>194</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>3703</td>\n",
       "      <td>113</td>\n",
       "      <td>881</td>\n",
       "      <td>71</td>\n",
       "      <td>466</td>\n",
       "      <td>330</td>\n",
       "      <td>472</td>\n",
       "      <td>243</td>\n",
       "      <td>68</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>282</td>\n",
       "      <td>608</td>\n",
       "      <td>136</td>\n",
       "      <td>110</td>\n",
       "      <td>968</td>\n",
       "      <td>62</td>\n",
       "      <td>2064</td>\n",
       "      <td>289</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>6288</td>\n",
       "      <td>110</td>\n",
       "      <td>1447</td>\n",
       "      <td>92</td>\n",
       "      <td>500</td>\n",
       "      <td>340</td>\n",
       "      <td>98</td>\n",
       "      <td>232</td>\n",
       "      <td>85</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>387</td>\n",
       "      <td>737</td>\n",
       "      <td>149</td>\n",
       "      <td>94</td>\n",
       "      <td>1107</td>\n",
       "      <td>45</td>\n",
       "      <td>2419</td>\n",
       "      <td>460</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4848</td>\n",
       "      <td>144</td>\n",
       "      <td>1134</td>\n",
       "      <td>90</td>\n",
       "      <td>771</td>\n",
       "      <td>500</td>\n",
       "      <td>116</td>\n",
       "      <td>245</td>\n",
       "      <td>76</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>424</td>\n",
       "      <td>1985</td>\n",
       "      <td>125</td>\n",
       "      <td>101</td>\n",
       "      <td>579</td>\n",
       "      <td>51</td>\n",
       "      <td>2793</td>\n",
       "      <td>493</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>3780</td>\n",
       "      <td>129</td>\n",
       "      <td>1511</td>\n",
       "      <td>105</td>\n",
       "      <td>404</td>\n",
       "      <td>302</td>\n",
       "      <td>105</td>\n",
       "      <td>229</td>\n",
       "      <td>54</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>312</td>\n",
       "      <td>1077</td>\n",
       "      <td>91</td>\n",
       "      <td>69</td>\n",
       "      <td>475</td>\n",
       "      <td>63</td>\n",
       "      <td>2459</td>\n",
       "      <td>508</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>3892</td>\n",
       "      <td>98</td>\n",
       "      <td>1380</td>\n",
       "      <td>68</td>\n",
       "      <td>629</td>\n",
       "      <td>403</td>\n",
       "      <td>92</td>\n",
       "      <td>242</td>\n",
       "      <td>65</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>278</td>\n",
       "      <td>868</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "      <td>559</td>\n",
       "      <td>85</td>\n",
       "      <td>2366</td>\n",
       "      <td>400</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>2329</td>\n",
       "      <td>115</td>\n",
       "      <td>1983</td>\n",
       "      <td>98</td>\n",
       "      <td>648</td>\n",
       "      <td>299</td>\n",
       "      <td>111</td>\n",
       "      <td>252</td>\n",
       "      <td>79</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>301</td>\n",
       "      <td>1013</td>\n",
       "      <td>131</td>\n",
       "      <td>106</td>\n",
       "      <td>622</td>\n",
       "      <td>58</td>\n",
       "      <td>2282</td>\n",
       "      <td>413</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>1973</td>\n",
       "      <td>116</td>\n",
       "      <td>2896</td>\n",
       "      <td>99</td>\n",
       "      <td>594</td>\n",
       "      <td>334</td>\n",
       "      <td>84</td>\n",
       "      <td>210</td>\n",
       "      <td>85</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>266</td>\n",
       "      <td>1231</td>\n",
       "      <td>130</td>\n",
       "      <td>98</td>\n",
       "      <td>626</td>\n",
       "      <td>37</td>\n",
       "      <td>1769</td>\n",
       "      <td>210</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>1859</td>\n",
       "      <td>77</td>\n",
       "      <td>1904</td>\n",
       "      <td>79</td>\n",
       "      <td>495</td>\n",
       "      <td>275</td>\n",
       "      <td>76</td>\n",
       "      <td>271</td>\n",
       "      <td>76</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>270</td>\n",
       "      <td>798</td>\n",
       "      <td>37</td>\n",
       "      <td>86</td>\n",
       "      <td>2845</td>\n",
       "      <td>66</td>\n",
       "      <td>1523</td>\n",
       "      <td>223</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>1934</td>\n",
       "      <td>107</td>\n",
       "      <td>1605</td>\n",
       "      <td>80</td>\n",
       "      <td>516</td>\n",
       "      <td>255</td>\n",
       "      <td>59</td>\n",
       "      <td>236</td>\n",
       "      <td>62</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp  NASA_Exceptional_Engineering_Achievement_Medal  \\\n",
       "0  2019-01-01                                             336   \n",
       "1  2019-02-01                                             318   \n",
       "2  2019-03-01                                             234   \n",
       "3  2019-04-01                                             259   \n",
       "4  2019-05-01                                             218   \n",
       "5  2019-06-01                                             271   \n",
       "6  2019-07-01                                             406   \n",
       "7  2019-08-01                                             361   \n",
       "8  2019-09-01                                             278   \n",
       "9  2019-10-01                                             280   \n",
       "10 2019-11-01                                             404   \n",
       "11 2019-12-01                                             282   \n",
       "12 2020-01-01                                             387   \n",
       "13 2020-02-01                                             424   \n",
       "14 2020-03-01                                             312   \n",
       "15 2020-04-01                                             278   \n",
       "16 2020-05-01                                             301   \n",
       "17 2020-06-01                                             266   \n",
       "18 2020-07-01                                             270   \n",
       "\n",
       "    Laureus_Lifetime_Achievement_Award  Filmic_Achievement  \\\n",
       "0                                  757                  99   \n",
       "1                                 2050                 130   \n",
       "2                                  724                 104   \n",
       "3                                  778                  99   \n",
       "4                                  780                  90   \n",
       "5                                  500                  91   \n",
       "6                                  520                 114   \n",
       "7                                  595                  91   \n",
       "8                                  603                  91   \n",
       "9                                  747                 139   \n",
       "10                                 650                 138   \n",
       "11                                 608                 136   \n",
       "12                                 737                 149   \n",
       "13                                1985                 125   \n",
       "14                                1077                  91   \n",
       "15                                 868                 112   \n",
       "16                                1013                 131   \n",
       "17                                1231                 130   \n",
       "18                                 798                  37   \n",
       "\n",
       "    TCA_Award_for_Outstanding_Achievement_in_Sports  \\\n",
       "0                                               100   \n",
       "1                                               102   \n",
       "2                                               108   \n",
       "3                                                97   \n",
       "4                                                76   \n",
       "5                                                95   \n",
       "6                                                89   \n",
       "7                                                95   \n",
       "8                                                86   \n",
       "9                                               113   \n",
       "10                                              113   \n",
       "11                                              110   \n",
       "12                                               94   \n",
       "13                                              101   \n",
       "14                                               69   \n",
       "15                                              118   \n",
       "16                                              106   \n",
       "17                                               98   \n",
       "18                                               86   \n",
       "\n",
       "    Latin_Grammy_Lifetime_Achievement_Award  Confidence_Bay  \\\n",
       "0                                       376              61   \n",
       "1                                       550              52   \n",
       "2                                       436              77   \n",
       "3                                       365              67   \n",
       "4                                       391              63   \n",
       "5                                       372              45   \n",
       "6                                       411              64   \n",
       "7                                       577              64   \n",
       "8                                       665              53   \n",
       "9                                       550              61   \n",
       "10                                      753              68   \n",
       "11                                      968              62   \n",
       "12                                     1107              45   \n",
       "13                                      579              51   \n",
       "14                                      475              63   \n",
       "15                                      559              85   \n",
       "16                                      622              58   \n",
       "17                                      626              37   \n",
       "18                                     2845              66   \n",
       "\n",
       "    Wechsler_Individual_Achievement_Test  \\\n",
       "0                                   2072   \n",
       "1                                   2264   \n",
       "2                                   2764   \n",
       "3                                   3386   \n",
       "4                                   2824   \n",
       "5                                   2048   \n",
       "6                                   1755   \n",
       "7                                   1778   \n",
       "8                                   2222   \n",
       "9                                   3143   \n",
       "10                                  2961   \n",
       "11                                  2064   \n",
       "12                                  2419   \n",
       "13                                  2793   \n",
       "14                                  2459   \n",
       "15                                  2366   \n",
       "16                                  2282   \n",
       "17                                  1769   \n",
       "18                                  1523   \n",
       "\n",
       "    Laurel_Award_for_TV_Writing_Achievement  \\\n",
       "0                                       264   \n",
       "1                                       250   \n",
       "2                                       206   \n",
       "3                                       228   \n",
       "4                                       222   \n",
       "5                                       129   \n",
       "6                                       156   \n",
       "7                                       192   \n",
       "8                                       190   \n",
       "9                                       189   \n",
       "10                                      194   \n",
       "11                                      289   \n",
       "12                                      460   \n",
       "13                                      493   \n",
       "14                                      508   \n",
       "15                                      400   \n",
       "16                                      413   \n",
       "17                                      210   \n",
       "18                                      223   \n",
       "\n",
       "    Computerized_Achievement_Levels_Test  ...  Confidence_Man_(band)  \\\n",
       "0                                     58  ...                   4139   \n",
       "1                                     50  ...                   2533   \n",
       "2                                     53  ...                   3371   \n",
       "3                                     45  ...                   2708   \n",
       "4                                     40  ...                   4209   \n",
       "5                                     42  ...                   3628   \n",
       "6                                     61  ...                   2038   \n",
       "7                                     43  ...                   1637   \n",
       "8                                     48  ...                   1535   \n",
       "9                                     53  ...                   1529   \n",
       "10                                    55  ...                   3703   \n",
       "11                                    57  ...                   6288   \n",
       "12                                    51  ...                   4848   \n",
       "13                                    55  ...                   3780   \n",
       "14                                    42  ...                   3892   \n",
       "15                                    32  ...                   2329   \n",
       "16                                    38  ...                   1973   \n",
       "17                                    75  ...                   1859   \n",
       "18                                    65  ...                   1934   \n",
       "\n",
       "    Lasker-Koshland_Special_Achievement_Award_in_Medical_Science  \\\n",
       "0                                                 131              \n",
       "1                                                 135              \n",
       "2                                                 128              \n",
       "3                                                  94              \n",
       "4                                                 107              \n",
       "5                                                 130              \n",
       "6                                                 112              \n",
       "7                                                 118              \n",
       "8                                                 132              \n",
       "9                                                 167              \n",
       "10                                                113              \n",
       "11                                                110              \n",
       "12                                                144              \n",
       "13                                                129              \n",
       "14                                                 98              \n",
       "15                                                115              \n",
       "16                                                116              \n",
       "17                                                 77              \n",
       "18                                                107              \n",
       "\n",
       "    Confidence_Man_(Lost)  Confidence,_West_Virginia  TrueAchievements  \\\n",
       "0                    1018                         69               355   \n",
       "1                    1151                         69               377   \n",
       "2                    1289                         84               350   \n",
       "3                    1119                        101               409   \n",
       "4                    1388                         57               302   \n",
       "5                    1219                         72               413   \n",
       "6                    1097                         60               429   \n",
       "7                    1008                         48               400   \n",
       "8                    1114                         94               400   \n",
       "9                    1201                        109               408   \n",
       "10                    881                         71               466   \n",
       "11                   1447                         92               500   \n",
       "12                   1134                         90               771   \n",
       "13                   1511                        105               404   \n",
       "14                   1380                         68               629   \n",
       "15                   1983                         98               648   \n",
       "16                   2896                         99               594   \n",
       "17                   1904                         79               495   \n",
       "18                   1605                         80               516   \n",
       "\n",
       "    Laurence_Olivier_Award_for_Outstanding_Achievement_in_an_Affiliate_Theatre  \\\n",
       "0                                                 284                            \n",
       "1                                                 193                            \n",
       "2                                                 447                            \n",
       "3                                                 530                            \n",
       "4                                                 306                            \n",
       "5                                                 432                            \n",
       "6                                                 305                            \n",
       "7                                                 321                            \n",
       "8                                                 521                            \n",
       "9                                                 402                            \n",
       "10                                                330                            \n",
       "11                                                340                            \n",
       "12                                                500                            \n",
       "13                                                302                            \n",
       "14                                                403                            \n",
       "15                                                299                            \n",
       "16                                                334                            \n",
       "17                                                275                            \n",
       "18                                                255                            \n",
       "\n",
       "    Major_achievements_in_roller_hockey_by_nation  \\\n",
       "0                                              84   \n",
       "1                                              95   \n",
       "2                                              89   \n",
       "3                                             102   \n",
       "4                                              92   \n",
       "5                                              89   \n",
       "6                                             143   \n",
       "7                                              88   \n",
       "8                                              73   \n",
       "9                                             108   \n",
       "10                                            472   \n",
       "11                                             98   \n",
       "12                                            116   \n",
       "13                                            105   \n",
       "14                                             92   \n",
       "15                                            111   \n",
       "16                                             84   \n",
       "17                                             76   \n",
       "18                                             59   \n",
       "\n",
       "    Differential_Education_Achievement  Juno_International_Achievement_Award  \\\n",
       "0                                  255                                    61   \n",
       "1                                  317                                    54   \n",
       "2                                  434                                    77   \n",
       "3                                  370                                    68   \n",
       "4                                  332                                    56   \n",
       "5                                  261                                    49   \n",
       "6                                  299                                    75   \n",
       "7                                  251                                    70   \n",
       "8                                  184                                    56   \n",
       "9                                  220                                    65   \n",
       "10                                 243                                    68   \n",
       "11                                 232                                    85   \n",
       "12                                 245                                    76   \n",
       "13                                 229                                    54   \n",
       "14                                 242                                    65   \n",
       "15                                 252                                    79   \n",
       "16                                 210                                    85   \n",
       "17                                 271                                    76   \n",
       "18                                 236                                    62   \n",
       "\n",
       "    Iran_Nuclear_Achievements_Protection_Act  \n",
       "0                                        111  \n",
       "1                                        107  \n",
       "2                                        127  \n",
       "3                                        115  \n",
       "4                                        135  \n",
       "5                                        169  \n",
       "6                                        234  \n",
       "7                                        177  \n",
       "8                                        139  \n",
       "9                                        217  \n",
       "10                                       211  \n",
       "11                                       187  \n",
       "12                                       313  \n",
       "13                                       120  \n",
       "14                                       160  \n",
       "15                                       222  \n",
       "16                                       137  \n",
       "17                                       137  \n",
       "18                                       105  \n",
       "\n",
       "[19 rows x 292 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "def create_dataframe(name_file):\n",
    "    \"\"\"\n",
    "    Creates a dataframe from a text file\n",
    "    param: name_file: name of the text file\n",
    "    return: dataframe with the text file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(name_file, delimiter=\"\\t\", header=None, names=['Topics'])\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Take only starting from the second word in each row\n",
    "def remove_space(df):\n",
    "    return df['Topics'].apply(lambda x: x.strip().replace(' ', '_'))\n",
    "\n",
    "# Parse the topics into the URL format\n",
    "def parse_topics_into_df(df, start_time, end_time):\n",
    "    # change the spaces to underscores\n",
    "    df['url'] = np.zeros(len(df))\n",
    "    for index, row in df.iterrows():\n",
    "        topic_value = row['Topics']\n",
    "        df.loc[index, 'url'] = f'https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia.org/all-access/all-agents/{topic_value}/monthly/{start_time}/{end_time}'\n",
    "\n",
    "    return df\n",
    "\n",
    "# Create a new dataframe with timestamp from starting date to ending date\n",
    "def create_dataframe_timestamp(starting_date, ending_date):\n",
    "    df_timestamp = pd.DataFrame()\n",
    "    df_timestamp['Timestamp'] = pd.date_range(start=starting_date, end=ending_date, freq='MS')\n",
    "    return df_timestamp\n",
    "\n",
    "# Define a function to fetch data from the URL and handle errors\n",
    "def fetch_and_parse_url(url):\n",
    "    try:\n",
    "        request.urlopen(url).read()\n",
    "        return True\n",
    "    except request.HTTPError as e:\n",
    "        if e.code == 404:\n",
    "            return None  # or any other value or action you prefer for 404 errors\n",
    "        else:\n",
    "            return None  # or handle other HTTP errors as needed\n",
    "    except Exception as e:\n",
    "        \n",
    "        return None  # or handle other exceptions as needed\n",
    "\n",
    "def get_pageviews_wiki(url):\n",
    "    \"\"\"\n",
    "    Gets the weekly pageviews for one Wikipedia page in one language in the desired period\n",
    "    param: url: url of the Wikipedia page\n",
    "    param: start_date: beginning of the desired period \n",
    "    param: end_date: end of the desired period \n",
    "    return: dataframe column with the monthly pageviews\n",
    "    \"\"\"\n",
    "    html = request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    site_json=json.loads(soup.text)\n",
    "    df=pd.DataFrame(site_json['items'])\n",
    "    df=df['views']\n",
    "    return df\n",
    "\n",
    "def scrape_pageviews(df):\n",
    "    pageview = pd.DataFrame()\n",
    "    pageview['Timestamp'] = create_dataframe_timestamp('2019-01-01', '2020-07-31')['Timestamp']\n",
    "\n",
    "    # Loop through the rows of the DataFrame and append the results of the function to the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        url = row['url']\n",
    "        if fetch_and_parse_url(url):\n",
    "            pageview[row['Topics']] = get_pageviews_wiki(url)\n",
    "\n",
    "    return pageview\n",
    "\n",
    "# Specify the path to your text file\n",
    "text_file_path = 'Esteem/esteem.txt'\n",
    "\n",
    "def create_dataframe_pageviews(name_file, start_time = '20190101', end_time = '20200731'):\n",
    "    \"\"\"\n",
    "    Creates a dataframe from a text file\n",
    "    param: name_file: name of the text file, start_time: beginning of the desired period, end_time: end of the desired period\n",
    "    \"\"\"\n",
    "    df_topic = create_dataframe(name_file)\n",
    "    df_topic['Topics'] = remove_space(df_topic)\n",
    "    df_topic = parse_topics_into_df(df_topic, start_time, end_time)\n",
    "    df_pageviews = scrape_pageviews(df_topic)\n",
    "    df_pageviews.fillna(0, inplace=True)\n",
    "    return df_pageviews, df_topic\n",
    "\n",
    "# Read the text file into a DataFrame\n",
    "df_pageviews, df_topic = create_dataframe_pageviews(text_file_path)\n",
    "print(type(df_pageviews))\n",
    "print(df_pageviews.shape)\n",
    "df_pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian\n",
      "_                       318\n",
      "                          3\n",
      "innovazione               1\n",
      "improvvisazione           1\n",
      "gamificazione             1\n",
      "etnobotanica              1\n",
      "Co-creazione              1\n",
      "sintesi                   1\n",
      "avanguardia               1\n",
      "storytelling              1\n",
      "scultura                  1\n",
      "immaginazione             1\n",
      "imprenditorialità         1\n",
      "curiosità                 1\n",
      "originalità               1\n",
      "collaborazione            1\n",
      "plasticità cerebrale      1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>url</th>\n",
       "      <th>Italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innovation</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>innovazione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagination</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>immaginazione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artistic_expression</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>design_thinking</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>creative_writing</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>theatricality_in_storytelling</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>designing_for_inclusive_entrepreneurship</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>the_future_of_creativity_in_biodesign</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>design_for_inclusive_technology</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>the_business_of_creative_consulting</td>\n",
       "      <td>https://wikimedia.org/api/rest_v1/metrics/page...</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Topics  \\\n",
       "0                                  innovation   \n",
       "1                                 imagination   \n",
       "2                         artistic_expression   \n",
       "3                             design_thinking   \n",
       "4                            creative_writing   \n",
       "..                                        ...   \n",
       "336             theatricality_in_storytelling   \n",
       "338  designing_for_inclusive_entrepreneurship   \n",
       "339     the_future_of_creativity_in_biodesign   \n",
       "341           design_for_inclusive_technology   \n",
       "352       the_business_of_creative_consulting   \n",
       "\n",
       "                                                   url        Italian  \n",
       "0    https://wikimedia.org/api/rest_v1/metrics/page...    innovazione  \n",
       "1    https://wikimedia.org/api/rest_v1/metrics/page...  immaginazione  \n",
       "2    https://wikimedia.org/api/rest_v1/metrics/page...              _  \n",
       "3    https://wikimedia.org/api/rest_v1/metrics/page...              _  \n",
       "4    https://wikimedia.org/api/rest_v1/metrics/page...              _  \n",
       "..                                                 ...            ...  \n",
       "336  https://wikimedia.org/api/rest_v1/metrics/page...              _  \n",
       "338  https://wikimedia.org/api/rest_v1/metrics/page...              _  \n",
       "339  https://wikimedia.org/api/rest_v1/metrics/page...              _  \n",
       "341  https://wikimedia.org/api/rest_v1/metrics/page...              _  \n",
       "352  https://wikimedia.org/api/rest_v1/metrics/page...              _  \n",
       "\n",
       "[336 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label_in_language(english_label, target_language):\n",
    "    # Endpoint URL for the Wikidata Query Service\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "    \n",
    "    # SPARQL query to get the item with the English label and its label in the target language\n",
    "    query = f'''\n",
    "    SELECT ?item ?itemLabel WHERE {{\n",
    "      ?item rdfs:label \"{english_label}\"@en.\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],{target_language}\". }}\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    '''\n",
    "    \n",
    "    # Headers for the request\n",
    "    headers = {\n",
    "        'User-Agent': 'MyBot/0.1 (myemail@example.com)',\n",
    "        'Accept': 'application/sparql-results+json'\n",
    "    }\n",
    "    \n",
    "    # Make the GET request\n",
    "    response = requests.get(url, headers=headers, params={'query': query, 'format': 'json'})\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results = data['results']['bindings']\n",
    "        if results:\n",
    "            # Return the item and its label in the target language\n",
    "            return results[0]['itemLabel']['value']\n",
    "        else:\n",
    "            return '_' # No label found for this language\n",
    "    else:\n",
    "        # Handle unsuccessful requests\n",
    "        response.raise_for_status()\n",
    "\n",
    "def change_Q(name):\n",
    "    if name.startswith('Q'):\n",
    "        return ' '\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "def translate_topics(df_topic, lang):\n",
    "    # Run through all the topics and get the translation in Italien and store it in a new column in the DataFrame\n",
    "    df_topic['Topics'] = df_topic['Topics'].str.lower()\n",
    "    df_topic['Italian'] = df_topic['Topics'].apply(lambda x: get_label_in_language(x, lang))\n",
    "    df_topic['Italian'].replace('No label found for this language', ' ', inplace=True)\n",
    "    df_topic['Italian'] = df_topic['Italian'].apply(lambda x: change_Q(x))\n",
    "    return df_topic\n",
    "\n",
    "df_topic = translate_topics(df_topic, 'it')\n",
    "# Count the number of topics that have a translation in Spanish\n",
    "print(df_topic['Italian'].value_counts())\n",
    "df_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
